{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Details\n",
    "\n",
    "### AIM : \n",
    "<b> To implement a language model which will perform better in playing the Hangman game as compared to the traditional models which depend on unigram,bigram and n-gram models</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating test beds\n",
    "##### Corpus Description\n",
    "<ul>\n",
    "<li>Name: <b> corncob_lowercase.txt.</b></li>\n",
    "<li>Description: <b> Contains 58110 lowercase english words</b></li>\n",
    "</ul>\n",
    "\n",
    "##### <b>Stratergy :</b> The model will evaluated using the concept of 10-cross validation\n",
    "<small>In k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k-1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method is that all observations are used for both training and validation, and each observation is used for validation exactly once.</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import operator\n",
    "words = []\n",
    "with open(\"train.txt\", mode=\"r\") as myFile:\n",
    "    for line in myFile:\n",
    "        try:\n",
    "            words.append(line.strip().encode(\"utf-8\"))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the Array into 10 equal parts\n",
    "\n",
    "<p>Since we would be doing 10-fold validation, we need to divide the shuffled list of words into 10 roughly equal parts. We would use 9 of them as train and 1 as test set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_parts = {}\n",
    "for i in xrange(len(words)):\n",
    "    key = i%10\n",
    "    if key in sub_parts:\n",
    "        sub_parts[key].append(words[i])\n",
    "    else:\n",
    "        sub_parts[key] = [words[i]]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating alphabet probabilities in the list of words\n",
    "\n",
    "<p>This function returns the probability s of a particular alphabet, calculated on the basis of its occurence in the word list passed it to it.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def count_alpha_occurence(list_of_words):\n",
    "    freq_dict = {}\n",
    "    total = 0\n",
    "    for word in list_of_words:\n",
    "        for char in word:\n",
    "            total += 1\n",
    "            if char in freq_dict:\n",
    "                freq_dict[char] = freq_dict[char] + 1\n",
    "            else:\n",
    "                freq_dict[char] = 1\n",
    "    for key in freq_dict:\n",
    "        freq_dict[key] = float(freq_dict[key])/total\n",
    "    \n",
    "    # sorting the dictionary based on values and reversing it to have the list of alphabets in decreasing order of their usage\n",
    "    freq_dict =  sorted(freq_dict.items(), key=operator.itemgetter(1),reverse=True)\n",
    "    return freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the conditional probabilties of an alphabet\n",
    "\n",
    "<p> For a given a alphabet 'a' it returns a dictionary where key is 'b' and value is the probability of b occuring in a word given that 'a' is present in the word. This is to exploit the fact that occurence of an alphabet depends on the company it keeps.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal Details\n",
    "\n",
    "<ol>\n",
    "    <li>Name: <b>G V Sandeep</b></li>\n",
    "    <li>College: <b>BITS - Pilani, Hyderabad Campus</b></li>\n",
    "    <li>Github: <a href=\"https://github.com/greetsandeep/\">greetsandeep</a></li>\n",
    "</ol>\n",
    "\n",
    "This code is open sourced and can be found at : <a href\"https://github.com/greetsandeep/ACM_SummerSchool/tree/master/Improvising%20Hangman\">Improvising Hangman</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
